{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16bc298b-e6e8-4ede-bd4c-8e12fac1bc12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Desafio técnico MINEHR\n",
    "\n",
    "### Por: Katia Cardoso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4880b622-eeb9-4e6d-b184-f834a7e3c08b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Importação de diferentes bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee5be4d1-8d90-4dbf-9b6a-15ac0ea67d88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# URL do arquivo CSV\n",
    "url_csv = 'https://storage.googleapis.com/desafio-ed/ingestion/base_colaboradores_2022.csv'\n",
    "# URL do arquivo Excel (.xlsx)\n",
    "url_excel = 'https://storage.googleapis.com/desafio-ed/ingestion/base_colaboradores_2023.xlsx'\n",
    "\n",
    "# Importando dados do Excel Online\n",
    "df_xlsx = pd.read_excel(url_excel)\n",
    "# Importando dados do CSV com codificação \"latin-1\" e separador \";\"\n",
    "df_csv = pd.read_csv(url_csv, encoding='latin-1', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1703bc43-1d0e-4d21-b6af-96519fafacee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Padronização dos nomes das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1845e35-e459-4dee-bb70-adf7889f453a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomes das colunas de df_csv antes dos ajustes:\nIndex(['Matrícula    ', 'MÊS REFERENCIA', 'FUNCIONARIO', 'DATA ADMISSAO',\n       'NACIONALIDADE', 'DATA DEMISSAO', 'ESTADO CIVIL', 'SEXO', 'CARGO',\n       'EMPRESA', 'DATA NASCIMENTO'],\n      dtype='object')\n\nNomes das colunas de df_excel antes dos ajustes:\nIndex(['mês referência', 'matricula', 'data admissao', 'funcionario',\n       'nacionalidade', 'estado civil', 'sexo', 'cargo', 'empresa',\n       'data de nascimento', 'data demissao'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Imprimir os nomes das colunas dos DataFrames\n",
    "print(\"Nomes das colunas de df_csv antes dos ajustes:\")\n",
    "print(df_csv.columns)\n",
    "\n",
    "print(\"\\nNomes das colunas de df_excel antes dos ajustes:\")\n",
    "print(df_xlsx.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ae010b8-6312-4432-b707-f046482de157",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas diferentes nos DataFrames: []\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "# Função para normalizar nomes de colunas\n",
    "def normalize_column_names(df):\n",
    "    # Normalizar nomes das colunas (acentos, minúsculas e espaços)\n",
    "    normalized_columns = [unidecode(col).lower().strip().replace(' ', '_') for col in df.columns]\n",
    "    df.columns = normalized_columns\n",
    "    return df\n",
    "\n",
    "# Normalizar nomes das colunas para ambos os DataFrames\n",
    "df_csv = normalize_column_names(df_csv)\n",
    "df_xlsx = normalize_column_names(df_xlsx)\n",
    "\n",
    "# Modificar o nome da coluna \"data_de_nascimento\" no DataFrame Excel\n",
    "df_xlsx.rename(columns={'data_de_nascimento': 'data_nascimento'}, inplace=True)\n",
    "\n",
    "# Verificar se os nomes das colunas são idênticos\n",
    "if df_csv.columns.equals(df_xlsx.columns):\n",
    "    # Se os nomes das colunas são idênticos, reorganize as colunas\n",
    "    df_csv = df_csv[df_xlsx.columns]\n",
    "else:\n",
    "    # Imprimir as colunas que são diferentes\n",
    "    different_columns = [col for col in df_csv.columns if col not in df_xlsx.columns]\n",
    "    print(f\"Colunas diferentes nos DataFrames: {different_columns}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d647a463-6bb0-4b54-934a-9aee1b1ce075",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomes das colunas de df_csv apos ajustes:\nIndex(['matricula', 'mes_referencia', 'funcionario', 'data_admissao',\n       'nacionalidade', 'data_demissao', 'estado_civil', 'sexo', 'cargo',\n       'empresa', 'data_nascimento'],\n      dtype='object')\n\nNomes das colunas de df_excel apos ajustes:\nIndex(['mes_referencia', 'matricula', 'data_admissao', 'funcionario',\n       'nacionalidade', 'estado_civil', 'sexo', 'cargo', 'empresa',\n       'data_nascimento', 'data_demissao'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Imprimir os nomes das colunas dos DataFrames\n",
    "print(\"Nomes das colunas de df_csv apos ajustes:\")\n",
    "print(df_csv.columns)\n",
    "\n",
    "print(\"\\nNomes das colunas de df_excel apos ajustes:\")\n",
    "print(df_xlsx.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cdfb512-a02c-486a-b834-04eb083cb30c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## União dos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8280008f-ddcb-4e60-851d-bacc7cab4ee9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matricula</th>\n",
       "      <th>mes_referencia</th>\n",
       "      <th>funcionario</th>\n",
       "      <th>data_admissao</th>\n",
       "      <th>nacionalidade</th>\n",
       "      <th>data_demissao</th>\n",
       "      <th>estado_civil</th>\n",
       "      <th>sexo</th>\n",
       "      <th>cargo</th>\n",
       "      <th>empresa</th>\n",
       "      <th>data_nascimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>28/02/2022</td>\n",
       "      <td>Colaborador 27</td>\n",
       "      <td>05/12/2005</td>\n",
       "      <td>brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Casado</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Eletr Lv Transmissao Iii</td>\n",
       "      <td>Empresa 6</td>\n",
       "      <td>01/01/1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>31/01/2022</td>\n",
       "      <td>Colaborador 28</td>\n",
       "      <td>14/04/2003</td>\n",
       "      <td>brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solteiro</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>Coord Tesouraria</td>\n",
       "      <td>Empresa 5</td>\n",
       "      <td>01/04/1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>28/02/2022</td>\n",
       "      <td>Colaborador 28</td>\n",
       "      <td>14/04/2003</td>\n",
       "      <td>brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Casado</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>Coord Tesouraria</td>\n",
       "      <td>Empresa 5</td>\n",
       "      <td>01/04/1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>31/03/2022</td>\n",
       "      <td>Colaborador 28</td>\n",
       "      <td>14/04/2003</td>\n",
       "      <td>brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solteiro</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>Coord Tesouraria</td>\n",
       "      <td>Empresa 2</td>\n",
       "      <td>01/04/1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>Colaborador 28</td>\n",
       "      <td>14/04/2003</td>\n",
       "      <td>brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solteiro</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>Coord Tesouraria</td>\n",
       "      <td>Empresa 2</td>\n",
       "      <td>01/04/1979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matricula mes_referencia  ...    empresa data_nascimento\n",
       "0         27     28/02/2022  ...  Empresa 6      01/01/1977\n",
       "1         28     31/01/2022  ...  Empresa 5      01/04/1979\n",
       "2         28     28/02/2022  ...  Empresa 5      01/04/1979\n",
       "3         28     31/03/2022  ...  Empresa 2      01/04/1979\n",
       "4         28     30/04/2022  ...  Empresa 2      01/04/1979\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenar os DataFrames por linhas (um abaixo do outro)\n",
    "df_final = pd.concat([df_csv, df_xlsx], ignore_index=True)\n",
    "\n",
    "# Salvando o DataFrame como um arquivo CSV\n",
    "df_final.to_csv('df_final.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Visualizando as primeiras 5 linhas do DataFrame\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d486a60-4004-4fc7-acab-d7a8dbddc745",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas csv : 20054\nNúmero de colunas csv: 11 \n\nNúmero de linhas xlsx: 27297\nNúmero de colunas xlsx : 11 \n \nNúmero de linhas final: 47351\nNúmero de colunas final: 11\n"
     ]
    }
   ],
   "source": [
    "#Verificação do numero de linhas e colunas arquivo .csv\n",
    "num_linhas_csv, num_colunas_csv = df_csv.shape\n",
    "print(f'Número de linhas csv : {num_linhas_csv}')\n",
    "print(f'Número de colunas csv: {num_colunas_csv} \\n')\n",
    "\n",
    "\n",
    "#Verificação do numero de linhas e colunas arquivo .xlsx\n",
    "num_linhas_xlsx, num_colunas_xlsx = df_xlsx.shape\n",
    "print(f'Número de linhas xlsx: {num_linhas_xlsx}')\n",
    "print(f'Número de colunas xlsx : {num_colunas_xlsx} \\n ')\n",
    "\n",
    "#Verificação do numero de linhas e colunas arquivo final\n",
    "num_linhas, num_colunas = df_final.shape\n",
    "print(f'Número de linhas final: {num_linhas}')\n",
    "print(f'Número de colunas final: {num_colunas}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b1db9ad-da91-4524-8e9c-eeb4019fcc26",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Conversão para um DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68d732de-5a21-44c3-b88b-777c7a59da2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 47351 entries, 0 to 47350\nData columns (total 11 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   matricula        47351 non-null  int64 \n 1   mes_referencia   47351 non-null  object\n 2   funcionario      47351 non-null  object\n 3   data_admissao    47351 non-null  object\n 4   nacionalidade    47346 non-null  object\n 5   data_demissao    436 non-null    object\n 6   estado_civil     47116 non-null  object\n 7   sexo             47351 non-null  object\n 8   cargo            47351 non-null  object\n 9   empresa          47351 non-null  object\n 10  data_nascimento  47351 non-null  object\ndtypes: int64(1), object(10)\nmemory usage: 4.0+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "# Verificação dos tipos de dados das colunas\n",
    "print(df_final.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14fa7b57-d425-40d5-98aa-6a14d7e4b8e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.types as t\n",
    "\n",
    "# Conversão do tipo de dados das colunas com o tipo 'object' para 'str'\n",
    "for col in df_final.columns:\n",
    "    if df_final[col].dtype == 'object':\n",
    "        df_final[col] = df_final[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da9a24d5-1912-4d27-94eb-5174daec8147",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- matricula: long (nullable = true)\n |-- mes_referencia: string (nullable = true)\n |-- funcionario: string (nullable = true)\n |-- data_admissao: string (nullable = true)\n |-- nacionalidade: string (nullable = true)\n |-- data_demissao: string (nullable = true)\n |-- estado_civil: string (nullable = true)\n |-- sexo: string (nullable = true)\n |-- cargo: string (nullable = true)\n |-- empresa: string (nullable = true)\n |-- data_nascimento: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Conversão do DataFrame do Pandas para um DataFrame do Spark\n",
    "spark_df = spark.createDataFrame(df_final)\n",
    "\n",
    "# Exiba o esquema do DataFrame Spark\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8b2a5d0-717c-417a-849f-5009345964d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+--------------+-------------+-------------+-------------+------------+---------+--------------------+---------+---------------+\n|matricula|mes_referencia|   funcionario|data_admissao|nacionalidade|data_demissao|estado_civil|     sexo|               cargo|  empresa|data_nascimento|\n+---------+--------------+--------------+-------------+-------------+-------------+------------+---------+--------------------+---------+---------------+\n|       27|    28/02/2022|Colaborador 27|   05/12/2005|     brasil  |          nan|      Casado|Masculino|Eletr Lv Transmis...|Empresa 6|     01/01/1977|\n|       28|    31/01/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 5|     01/04/1979|\n|       28|    28/02/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|      Casado| Feminino|    Coord Tesouraria|Empresa 5|     01/04/1979|\n|       28|    31/03/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    30/04/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    31/05/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    30/06/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    31/07/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    31/08/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    30/09/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    31/10/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    30/11/2022|Colaborador 28|   14/04/2003|     brasil  |          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    31/12/2022|Colaborador 28|   14/04/2003|       brasil|          nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       31|    28/02/2022|Colaborador 31|   19/12/2005|       Brasil|          nan|      Casado|Masculino|Sup Operacao Usina I|Empresa 6|     04/03/1987|\n|       34|    28/02/2022|Colaborador 34|   03/01/2006|       Brasil|          nan|      casado|Masculino|            Soldador|Empresa 6|     03/04/1984|\n|       44|    28/02/2022|Colaborador 44|   20/03/2006|       Brasil|          nan|      casado|Masculino|Sup Projetos Obra...|Empresa 6|     28/08/1984|\n|       53|    31/01/2022|Colaborador 53|   10/06/2008|       Brasil|          nan|      casado|Masculino|Ger Compras Mater...|Empresa 2|     06/08/1982|\n|       53|    28/02/2022|Colaborador 53|   10/06/2008|       Brasil|          nan|      casado|Masculino|Ger Compras Mater...|Empresa 5|     06/08/1982|\n|       53|    31/03/2022|Colaborador 53|   10/06/2008|       Brasil|          nan|      casado|Masculino|Ger Compras Mater...|Empresa 2|     06/08/1982|\n|       53|    30/04/2022|Colaborador 53|   10/06/2008|       Brasil|          nan|      casado|Masculino|Ger Compras Mater...|Empresa 2|     06/08/1982|\n+---------+--------------+--------------+-------------+-------------+-------------+------------+---------+--------------------+---------+---------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Exiba o DataFrame ajustado\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec98bef-5a90-4e20-8fc6-409a4cb4ca8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Verificação do tipo de dados do DataFrame\n",
    "print(type(spark_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb9d7d1d-8989-4c2d-ba71-1995924501a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('matricula', 'bigint'), ('mes_referencia', 'string'), ('funcionario', 'string'), ('data_admissao', 'string'), ('nacionalidade', 'string'), ('data_demissao', 'string'), ('estado_civil', 'string'), ('sexo', 'string'), ('cargo', 'string'), ('empresa', 'string'), ('data_nascimento', 'string')]\n"
     ]
    }
   ],
   "source": [
    "# Imprime o esquema do DataFrame\n",
    "print(spark_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91665fc9-df72-4989-a930-64a89a6150e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Padronização dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32585c30-94bc-4c74-9782-dcf367ac3e6c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " - trim(col(coluna)) remove os espaços em branco no início e no final de cada string na coluna\n",
    " - initcap() coloca as iniciais das palavras em maiúsculas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b72aaeb7-884c-44e8-b399-87d3d5f711a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+--------------+-------------+-------------+-------------+------------+---------+--------------------+---------+---------------+\n|matricula|mes_referencia|   funcionario|data_admissao|nacionalidade|data_demissao|estado_civil|     sexo|               cargo|  empresa|data_nascimento|\n+---------+--------------+--------------+-------------+-------------+-------------+------------+---------+--------------------+---------+---------------+\n|       27|    28/02/2022|Colaborador 27|   05/12/2005|       Brasil|          Nan|      Casado|Masculino|Eletr Lv Transmis...|Empresa 6|     01/01/1977|\n|       28|    31/01/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 5|     01/04/1979|\n|       28|    28/02/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|      Casado| Feminino|    Coord Tesouraria|Empresa 5|     01/04/1979|\n|       28|    31/03/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    30/04/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    31/05/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    30/06/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    31/07/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    31/08/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    30/09/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    31/10/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    30/11/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       28|    31/12/2022|Colaborador 28|   14/04/2003|       Brasil|          Nan|    Solteiro| Feminino|    Coord Tesouraria|Empresa 2|     01/04/1979|\n|       31|    28/02/2022|Colaborador 31|   19/12/2005|       Brasil|          Nan|      Casado|Masculino|Sup Operacao Usina I|Empresa 6|     04/03/1987|\n|       34|    28/02/2022|Colaborador 34|   03/01/2006|       Brasil|          Nan|      Casado|Masculino|            Soldador|Empresa 6|     03/04/1984|\n|       44|    28/02/2022|Colaborador 44|   20/03/2006|       Brasil|          Nan|      Casado|Masculino|Sup Projetos Obra...|Empresa 6|     28/08/1984|\n|       53|    31/01/2022|Colaborador 53|   10/06/2008|       Brasil|          Nan|      Casado|Masculino|Ger Compras Mater...|Empresa 2|     06/08/1982|\n|       53|    28/02/2022|Colaborador 53|   10/06/2008|       Brasil|          Nan|      Casado|Masculino|Ger Compras Mater...|Empresa 5|     06/08/1982|\n|       53|    31/03/2022|Colaborador 53|   10/06/2008|       Brasil|          Nan|      Casado|Masculino|Ger Compras Mater...|Empresa 2|     06/08/1982|\n|       53|    30/04/2022|Colaborador 53|   10/06/2008|       Brasil|          Nan|      Casado|Masculino|Ger Compras Mater...|Empresa 2|     06/08/1982|\n+---------+--------------+--------------+-------------+-------------+-------------+------------+---------+--------------------+---------+---------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import trim, initcap, col\n",
    "\n",
    "# Lista de todas as colunas do DataFrame\n",
    "columns = spark_df.columns\n",
    "\n",
    "# Lista de colunas textuais \n",
    "textual_columns = ['mes_referencia', 'funcionario', 'data_admissao', 'nacionalidade', 'data_demissao', 'estado_civil', 'sexo', 'cargo', 'empresa', 'data_nascimento']  \n",
    "\n",
    "# Aplicação das transformações nas colunas textuais\n",
    "for column in textual_columns:\n",
    "    spark_df = spark_df.withColumn(column, initcap(trim(col(column))))\n",
    "\n",
    "# Mostra o DataFrame após as transformações\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8efe7f7-de05-4898-95ec-7313b9bb56d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "verificar requisito: Para as colunas numéricas, certifique-se que tenha no máximo 4 casa decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4267cc2-ec33-40f9-8a43-234a68e78194",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----------+-------------+-------------+-------------+------------+----+-----+-------+---------------+-----------+\n|matricula|mes_referencia|funcionario|data_admissao|nacionalidade|data_demissao|estado_civil|sexo|cargo|empresa|data_nascimento|comprimento|\n+---------+--------------+-----------+-------------+-------------+-------------+------------+----+-----+-------+---------------+-----------+\n+---------+--------------+-----------+-------------+-------------+-------------+------------+----+-----+-------+---------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, length\n",
    "\n",
    "# Nome da coluna numérica \n",
    "numeric_columns = 'matricula'\n",
    "\n",
    "# Verificação do comprimento dos valores na coluna numérica\n",
    "spark_df.withColumn('comprimento', length(col(numeric_columns))).filter(col('comprimento') > 4).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Teste_Tecnico_MINEHR",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
